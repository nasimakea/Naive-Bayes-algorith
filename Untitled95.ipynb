{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUnR9O8Ur30u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
      ],
      "metadata": {
        "id": "BBBsiyg9r5Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jjZdqoVGr__l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "q-jIb7matCg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS"
      ],
      "metadata": {
        "id": "UvO7FMUAuEzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's say total employee be 100\n",
        "# employee with insurance= 40% 100"
      ],
      "metadata": {
        "id": "CamXoIgtuFrt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability_of_smoker_with_insurance=((40/100)*(70/100)*100)/100"
      ],
      "metadata": {
        "id": "4t3Idfv6uV-i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability_of_smoker_with_insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocijc4adu5_R",
        "outputId": "39d10ac2-9b3d-461f-f5aa-85b7c5c3b0e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27999999999999997"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percent_of_chance=(7/(25+7))*100\n"
      ],
      "metadata": {
        "id": "UPN5QTYNu81W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent_of_chance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXVIXYaovgoT",
        "outputId": "3840369e-4ff5-4653-b739-eee2019d3355"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.875"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1YIkU8_vhqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
      ],
      "metadata": {
        "id": "9LgCESfFv37b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbV26jJdv4qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "- The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the assumptions they make about the distribution of the features in the data.\n",
        "\n",
        "# Bernoulli Naive Bayes:\n",
        "\n",
        "- Assumption: Assumes that features are binary, meaning they take on only two possible values (0 or 1).\n",
        "\n",
        "- Use Cases: It is commonly used when dealing with binary data, such as document classification problems, where features represent the presence or absence of specific words.\n",
        "\n",
        "- Example:\n",
        "\n",
        "In a document classification task, each feature might represent the presence or absence of a particular word in the document.\n",
        "Mathematical Representation:\n",
        "\n",
        "Assumes that each feature follows a Bernoulli distribution (a discrete probability distribution for binary events).\n",
        "# Multinomial Naive Bayes:\n",
        "\n",
        "- Assumption: Assumes that features follow a multinomial distribution, which is suitable for discrete data where each feature represents the count or frequency of an event.\n",
        "\n",
        "- Use Cases: Commonly used in text classification tasks, where features represent the frequency of word occurrences.\n",
        "- Example:\n",
        "\n",
        "In text classification, the features could be the word counts in a document, and the assumption is that the features follow a multinomial distribution.\n",
        "Mathematical Representation:\n",
        "\n",
        "Assumes that each feature is represented by a multinomial distribution, which is a generalization of the binomial distribution to multiple categories."
      ],
      "metadata": {
        "id": "0Ig3dm2txlO1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4l9vpJ5Jx0tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. How does Bernoulli Naive Bayes handle missing values?"
      ],
      "metadata": {
        "id": "M3IbSR3Kx5rM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhoijYNex6aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "# Bernoulli Naive Bayes is generally not well-suited to handling missing values directly, as the model assumes that features are binary (taking values of 0 or 1). In a Bernoulli Naive Bayes model, the presence or absence of a feature is a crucial aspect, and missing values disrupt this binary representation.\n",
        "\n",
        "- When faced with missing values in a dataset, there are several strategies you can consider:\n",
        "\n",
        "# Imputation:\n",
        "\n",
        "One common approach is to impute missing values with some value, typically the mode (most frequent value) of the feature or a specific constant (e.g., 0). This way, you transform the data to fit the binary nature of Bernoulli Naive Bayes.\n",
        "# Feature Engineering:\n",
        "\n",
        "If the missing values are not missing at random and convey meaningful information, you might consider creating an additional binary feature indicating the presence or absence of missing values.\n",
        "# Dropping Instances:\n",
        "\n",
        "Another option is to exclude instances (rows) with missing values if the proportion of missing values is relatively small and does not significantly impact the dataset's representativeness.\n",
        "# Advanced Imputation Techniques:\n",
        "\n",
        "For more sophisticated handling of missing values, you can explore machine learning-based imputation techniques, such as k-Nearest Neighbors (KNN) imputation or matrix factorization methods."
      ],
      "metadata": {
        "id": "1l4Ia4EwyuwO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQ2vyIR-y5y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
      ],
      "metadata": {
        "id": "MD8rIEF3y-9p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VngFpkncy_uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "- Gaussian Naive Bayes can be used for multi-class classification. The Gaussian Naive Bayes algorithm is an extension of the Naive Bayes algorithm that is designed to handle continuous data, assuming that each feature follows a Gaussian (normal) distribution. While the original Naive Bayes algorithm is often used for binary and text classification, Gaussian Naive Bayes extends its applicability to problems with continuous numerical features.\n",
        "\n",
        "- In the context of multi-class classification, the Gaussian Naive Bayes model is adapted to handle multiple classes by using the probability estimates for each class and making predictions based on the class with the highest probability. The decision rule is essentially the same as in the binary case, but it is applied to multiple classes.\n",
        "\n",
        "# Here's a basic overview of how Gaussian Naive Bayes works for multi-class classification:\n",
        "\n",
        "# Training:\n",
        "\n",
        "- The model estimates the mean and variance of each feature for each class, assuming a Gaussian distribution.\n",
        "# Prediction:\n",
        "\n",
        "Given a set of features for a new instance, the model calculates the likelihood of the instance belonging to each class based on the Gaussian distribution parameters.\n",
        "\n",
        "The final class prediction is made by selecting the class with the highest probability."
      ],
      "metadata": {
        "id": "2ag9tJVmznVH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VMyyc_zz5Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Assignment:\n",
        "Data preparation:\n",
        "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
        "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
        "is spam or not based on several input features.\n",
        "\n",
        "Implementation:\n",
        "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
        "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
        "dataset. You should use the default hyperparameters for each classifier.\n",
        "Results:\n",
        "Report the following performance metrics for each classifier:\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1 score\n",
        "Discussion:\n",
        "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
        "the case? Are there any limitations of Naive Bayes that you observed?\n",
        "Conclusion:\n",
        "Summarise your findings and provide some suggestions for future work."
      ],
      "metadata": {
        "id": "P_2UvbH-0X1c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jp4yPbYD0aNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}